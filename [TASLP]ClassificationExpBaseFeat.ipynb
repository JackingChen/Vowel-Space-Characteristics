{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/jack/workspace/DisVoice/articulation/HYPERPARAM/Label.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  label_raw=label_raw.append(df_labels_TD)\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "/media/jack/workspace/DisVoice/utils_jack.py:443: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Info_name_sex=Info_name_sex.append(Info_name_sex_TD)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search path from  Features/ClassificationMerged_dfs/uniform_2_DKIndividual/ASD_DOCKID/*.pkl\n",
      "Read path from  ['Features/ClassificationMerged_dfs/uniform_2_DKIndividual/ASD_DOCKID/static_feautre_LOC.pkl', 'Features/ClassificationMerged_dfs/uniform_2_DKIndividual/ASD_DOCKID/dynamic_feature_phonation.pkl', 'Features/ClassificationMerged_dfs/uniform_2_DKIndividual/ASD_DOCKID/dynamic_feature_LOC.pkl']\n",
      "Read path from  ['Features/ClassificationMerged_dfs/uniform_2_DKIndividual/TD_DOCKID/static_feautre_LOC.pkl', 'Features/ClassificationMerged_dfs/uniform_2_DKIndividual/TD_DOCKID/dynamic_feature_phonation.pkl', 'Features/ClassificationMerged_dfs/uniform_2_DKIndividual/TD_DOCKID/dynamic_feature_LOC.pkl']\n",
      "Start classification\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.55\n",
      "The best parameters are : {'model__C': 1.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> Inter-Vowel Dispersion, label ASDTD ,UAR 0.48214285714285715\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5416666666666667\n",
      "The best parameters are : {'model__C': 100.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> Inter-Vowel Dispersion, label ASDTD ,UAR 0.4705128205128205\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5333333333333333\n",
      "The best parameters are : {'model__C': 25.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> Inter-Vowel Dispersion, label ASDTD ,UAR 0.47878787878787876\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.6\n",
      "The best parameters are : {'model__C': 75.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> formant dependency, label ASDTD ,UAR 0.5392857142857143\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.525\n",
      "The best parameters are : {'model__C': 25.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> formant dependency, label ASDTD ,UAR 0.4724358974358974\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5\n",
      "The best parameters are : {'model__C': 0.001, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> formant dependency, label ASDTD ,UAR 0.4492424242424243\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.575\n",
      "The best parameters are : {'model__C': 1.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> LOCDEP_columns, label ASDTD ,UAR 0.45714285714285713\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5\n",
      "The best parameters are : {'model__C': 0.001, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> LOCDEP_columns, label ASDTD ,UAR 0.46025641025641023\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.6166666666666666\n",
      "The best parameters are : {'model__C': 5.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> LOCDEP_columns, label ASDTD ,UAR 0.5689393939393939\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.65\n",
      "The best parameters are : {'model__C': 50.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> Intra-Vowel Dispersion, label ASDTD ,UAR 0.6107142857142858\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5\n",
      "The best parameters are : {'model__C': 0.001, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> Intra-Vowel Dispersion, label ASDTD ,UAR 0.46153846153846156\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5\n",
      "The best parameters are : {'model__C': 0.001, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> Intra-Vowel Dispersion, label ASDTD ,UAR 0.5\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.775\n",
      "The best parameters are : {'model__C': 1.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> GC[P]\\textsubscript{inv}, label ASDTD ,UAR 0.7821428571428571\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.6458333333333333\n",
      "The best parameters are : {'model__C': 1.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> GC[P]\\textsubscript{inv}, label ASDTD ,UAR 0.6346153846153846\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.7166666666666666\n",
      "The best parameters are : {'model__C': 10.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> GC[P]\\textsubscript{inv}, label ASDTD ,UAR 0.6340909090909091\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.75\n",
      "The best parameters are : {'model__C': 1.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> GC[P]\\textsubscript{part}, label ASDTD ,UAR 0.7464285714285714\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5583333333333333\n",
      "The best parameters are : {'model__C': 5.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> GC[P]\\textsubscript{part}, label ASDTD ,UAR 0.5089743589743589\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5\n",
      "The best parameters are : {'model__C': 0.001, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> GC[P]\\textsubscript{part}, label ASDTD ,UAR 0.3787878787878788\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.675\n",
      "The best parameters are : {'model__C': 1.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> Proximity[P], label ASDTD ,UAR 0.675\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.8083333333333333\n",
      "The best parameters are : {'model__C': 1.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> Proximity[P], label ASDTD ,UAR 0.8102564102564103\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.8375\n",
      "The best parameters are : {'model__C': 1.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> Proximity[P], label ASDTD ,UAR 0.843939393939394\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.625\n",
      "The best parameters are : {'model__C': 1.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> Convergence[P], label ASDTD ,UAR 0.6607142857142857\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5\n",
      "The best parameters are : {'model__C': 0.001, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> Convergence[P], label ASDTD ,UAR 0.46025641025641023\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.525\n",
      "The best parameters are : {'model__C': 1.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> Convergence[P], label ASDTD ,UAR 0.48484848484848486\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.75\n",
      "The best parameters are : {'model__C': 5.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> Syncrony[P], label ASDTD ,UAR 0.7321428571428572\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.6125\n",
      "The best parameters are : {'model__C': 10.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> Syncrony[P], label ASDTD ,UAR 0.5967948717948718\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5624999999999999\n",
      "The best parameters are : {'model__C': 10.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> Syncrony[P], label ASDTD ,UAR 0.5287878787878788\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5\n",
      "The best parameters are : {'model__C': 0.001, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> Proximity[VSC], label ASDTD ,UAR 0.45\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5375\n",
      "The best parameters are : {'model__C': 10.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> Proximity[VSC], label ASDTD ,UAR 0.4474358974358974\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.6791666666666666\n",
      "The best parameters are : {'model__C': 25.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> Proximity[VSC], label ASDTD ,UAR 0.5636363636363637\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.65\n",
      "The best parameters are : {'model__C': 1.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> GC[VSC]\\textsubscript{inv}, label ASDTD ,UAR 0.6107142857142858\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.7416666666666667\n",
      "The best parameters are : {'model__C': 10.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> GC[VSC]\\textsubscript{inv}, label ASDTD ,UAR 0.698076923076923\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.6083333333333332\n",
      "The best parameters are : {'model__C': 5.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> GC[VSC]\\textsubscript{inv}, label ASDTD ,UAR 0.5393939393939394\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.65\n",
      "The best parameters are : {'model__C': 5.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> GC[VSC]\\textsubscript{part}, label ASDTD ,UAR 0.6214285714285714\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5958333333333333\n",
      "The best parameters are : {'model__C': 5.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> GC[VSC]\\textsubscript{part}, label ASDTD ,UAR 0.5243589743589744\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.575\n",
      "The best parameters are : {'model__C': 25.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> GC[VSC]\\textsubscript{part}, label ASDTD ,UAR 0.4537878787878788\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.6\n",
      "The best parameters are : {'model__C': 1.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> Convergence[VSC], label ASDTD ,UAR 0.55\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.6\n",
      "The best parameters are : {'model__C': 5.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> Convergence[VSC], label ASDTD ,UAR 0.5974358974358974\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.55\n",
      "The best parameters are : {'model__C': 10.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> Convergence[VSC], label ASDTD ,UAR 0.5393939393939394\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.55\n",
      "The best parameters are : {'model__C': 5.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_lowMinimal_CSS >> Syncrony[VSC], label ASDTD ,UAR 0.3857142857142857\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.5125\n",
      "The best parameters are : {'model__C': 1.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_moderate_CSS >> Syncrony[VSC], label ASDTD ,UAR 0.4474358974358974\n",
      "=====================Cross validation start==================\n",
      "The best score with scoring parameter: 'r2' is 0.575\n",
      "The best parameters are : {'model__C': 5.0, 'model__kernel': 'rbf', 'model__probability': True, 'model__random_state': 1}\n",
      "Feature TD vs df_feature_high_CSS >> Syncrony[VSC], label ASDTD ,UAR 0.4590909090909091\n",
      "df_best_result_allThreeClassifiers\n",
      "                                                   ASDTD/SVC     f1\n",
      "TD vs df_feature_lowMinimal_CSS >> Inter-Vowel ...     0.482  0.462\n",
      "TD vs df_feature_moderate_CSS >> Inter-Vowel Di...     0.471  0.471\n",
      "TD vs df_feature_high_CSS >> Inter-Vowel Disper...     0.479  0.463\n",
      "TD vs df_feature_lowMinimal_CSS >> formant depe...     0.539  0.539\n",
      "TD vs df_feature_moderate_CSS >> formant depend...     0.472  0.453\n",
      "TD vs df_feature_high_CSS >> formant dependency        0.449  0.388\n",
      "TD vs df_feature_lowMinimal_CSS >> LOCDEP_columns      0.457  0.442\n",
      "TD vs df_feature_moderate_CSS >> LOCDEP_columns         0.46  0.429\n",
      "TD vs df_feature_high_CSS >> LOCDEP_columns            0.569  0.567\n",
      "TD vs df_feature_lowMinimal_CSS >> Intra-Vowel ...     0.611  0.609\n",
      "TD vs df_feature_moderate_CSS >> Intra-Vowel Di...     0.462  0.379\n",
      "TD vs df_feature_high_CSS >> Intra-Vowel Disper...       0.5  0.384\n",
      "TD vs df_feature_lowMinimal_CSS >> GC[P]\\textsu...     0.782  0.785\n",
      "TD vs df_feature_moderate_CSS >> GC[P]\\textsubs...     0.635  0.636\n",
      "TD vs df_feature_high_CSS >> GC[P]\\textsubscrip...     0.634  0.637\n",
      "TD vs df_feature_lowMinimal_CSS >> GC[P]\\textsu...     0.746  0.751\n",
      "TD vs df_feature_moderate_CSS >> GC[P]\\textsubs...     0.509  0.508\n",
      "TD vs df_feature_high_CSS >> GC[P]\\textsubscrip...     0.379  0.321\n",
      "TD vs df_feature_lowMinimal_CSS >> Proximity[P]        0.675  0.678\n",
      "TD vs df_feature_moderate_CSS >> Proximity[P]           0.81  0.799\n",
      "TD vs df_feature_high_CSS >> Proximity[P]              0.844  0.826\n",
      "TD vs df_feature_lowMinimal_CSS >> Convergence[P]      0.661  0.662\n",
      "TD vs df_feature_moderate_CSS >> Convergence[P]         0.46  0.429\n",
      "TD vs df_feature_high_CSS >> Convergence[P]            0.485  0.376\n",
      "TD vs df_feature_lowMinimal_CSS >> Syncrony[P]         0.732  0.729\n",
      "TD vs df_feature_moderate_CSS >> Syncrony[P]           0.597  0.598\n",
      "TD vs df_feature_high_CSS >> Syncrony[P]               0.529  0.524\n",
      "TD vs df_feature_lowMinimal_CSS >> Proximity[VSC]       0.45  0.346\n",
      "TD vs df_feature_moderate_CSS >> Proximity[VSC]        0.447  0.419\n",
      "TD vs df_feature_high_CSS >> Proximity[VSC]            0.564  0.564\n",
      "TD vs df_feature_lowMinimal_CSS >> GC[VSC]\\text...     0.611  0.609\n",
      "TD vs df_feature_moderate_CSS >> GC[VSC]\\textsu...     0.698  0.705\n",
      "TD vs df_feature_high_CSS >> GC[VSC]\\textsubscr...     0.539  0.515\n",
      "TD vs df_feature_lowMinimal_CSS >> GC[VSC]\\text...     0.621  0.615\n",
      "TD vs df_feature_moderate_CSS >> GC[VSC]\\textsu...     0.524  0.477\n",
      "TD vs df_feature_high_CSS >> GC[VSC]\\textsubscr...     0.454   0.43\n",
      "TD vs df_feature_lowMinimal_CSS >> Convergence[...      0.55  0.549\n",
      "TD vs df_feature_moderate_CSS >> Convergence[VSC]      0.597    0.6\n",
      "TD vs df_feature_high_CSS >> Convergence[VSC]          0.539  0.515\n",
      "TD vs df_feature_lowMinimal_CSS >> Syncrony[VSC]       0.386  0.345\n",
      "TD vs df_feature_moderate_CSS >> Syncrony[VSC]         0.447  0.419\n",
      "TD vs df_feature_high_CSS >> Syncrony[VSC]             0.459  0.418\n",
      "generated at RESULTS/Fusion_result/baselineFeats//Classification_uniform_2_DKIndividual.xlsx\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun 30 15:56:45 2021\n",
    "\n",
    "@author: jackchen\n",
    "\n",
    "\n",
    "    This script is only for TBMEB1 \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "from scipy.stats import spearmanr,pearsonr \n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from addict import Dict\n",
    "# import functions\n",
    "import argparse\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import sklearn.svm\n",
    "import torch\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from articulation.HYPERPARAM import phonewoprosody, Label\n",
    "from articulation.HYPERPARAM.PeopleSelect import SellectP_define\n",
    "import articulation.HYPERPARAM.FeatureSelect as FeatSel\n",
    "import articulation.HYPERPARAM.PaperNameMapping as PprNmeMp\n",
    "\n",
    "import articulation.articulation\n",
    "from sklearn.metrics import f1_score,recall_score,roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from itertools import combinations, dropwhile\n",
    "\n",
    "def Assert_labelfeature(feat_name,lab_name):\n",
    "    # =============================================================================\n",
    "    #     To check if the label match with feature\n",
    "    # =============================================================================\n",
    "    for i,n in enumerate(feat_name):\n",
    "        assert feat_name[i] == lab_name[i]\n",
    "\n",
    "def FilterFile_withinManualName(files,Manual_choosen_feature):\n",
    "    files_manualChoosen=[f  for f in files if os.path.basename(f).split(\".\")[0]  in Manual_choosen_feature]\n",
    "    return files_manualChoosen\n",
    "\n",
    "def Merge_dfs(df_1, df_2):\n",
    "    return pd.merge(df_1,df_2,left_index=True, right_index=True)\n",
    "\n",
    "def Add_label(df_formant_statistic,Label,label_choose='ADOS_cate_C'):\n",
    "    for people in df_formant_statistic.index:\n",
    "        bool_ind=Label.label_raw['name']==people\n",
    "        df_formant_statistic.loc[people,label_choose]=Label.label_raw.loc[bool_ind,label_choose].values\n",
    "    return df_formant_statistic\n",
    "\n",
    "def get_args():\n",
    "    # we add compulsary arguments as named arguments for readability\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--Feature_mode', default='Customized_feature',\n",
    "                        help='what kind of data you want to get')\n",
    "    parser.add_argument('--preprocess', default=True,\n",
    "                        help='')\n",
    "    parser.add_argument('--start_point', default=-1,\n",
    "                        help='In case that the program stop at certain point, we can resume the progress by setting this variable')\n",
    "    parser.add_argument('--experiment', default='gop_exp_ADOShappyDAAIKidallDeceiptformosaCSRC',\n",
    "                        help='If the mode is set to Session_phone_phf, you may need to determine the experiment used to generate the gop feature')\n",
    "    parser.add_argument('--pseudo', default=False,\n",
    "                        help='what kind of data you want to get')\n",
    "    parser.add_argument('--suffix', default=\"\",\n",
    "                        help='what kind of data you want to get')\n",
    "    parser.add_argument('--FS_method_str', default=None,\n",
    "                        help='Feature selection')\n",
    "    parser.add_argument('--UseManualCtxFeat', default=True,\n",
    "                        help='')\n",
    "    parser.add_argument('--Plot', default=True,\n",
    "                        help='')\n",
    "    parser.add_argument('--selectModelScoring', default='recall_macro',\n",
    "                        help='[recall_macro,accuracy]')\n",
    "    parser.add_argument('--Mergefeatures', default=False,\n",
    "                        help='')\n",
    "    parser.add_argument('--knn_weights', default='uniform',\n",
    "                            help='uniform distance')\n",
    "    parser.add_argument('--knn_neighbors', default=2,  type=int,\n",
    "                            help='path of the base directory')\n",
    "    parser.add_argument('--Reorder_type', default='DKIndividual',\n",
    "                            help='[DKIndividual, DKcriteria]')\n",
    "    parser.add_argument('--FeatureComb_mode', default='baselineFeats',\n",
    "                            help='[Add_UttLvl_feature, feat_comb3, feat_comb5, feat_comb6,feat_comb7, baselineFeats,Comb_dynPhonation,Comb_staticLOCDEP_dynamicLOCDEP_dynamicphonation]')\n",
    "    # parser.add_argument('--Add_UttLvl_feature', default=False,\n",
    "    #                         help='[DKIndividual, DKcriteria]')\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n",
    "args = get_args()\n",
    "start_point=args.start_point\n",
    "experiment=args.experiment\n",
    "knn_weights=args.knn_weights\n",
    "knn_neighbors=args.knn_neighbors\n",
    "Reorder_type=args.Reorder_type\n",
    "\n",
    "\n",
    "Session_level_all=Dict()\n",
    "# Discriminative analysis Main\n",
    "columns=[\n",
    "    'Divergence[within_covariance_norm(A:,i:,u:)]',\n",
    "    'Divergence[within_variance_norm(A:,i:,u:)]',    \n",
    "    'Divergence[between_covariance_norm(A:,i:,u:)]',    \n",
    "    'Divergence[between_variance_norm(A:,i:,u:)]',    \n",
    "    'Divergence[total_covariance_norm(A:,i:,u:)]', \n",
    "    'Divergence[total_variance_norm(A:,i:,u:)]',\n",
    "    'Divergence[sam_wilks_lin_norm(A:,i:,u:)]',    \n",
    "    'Divergence[pillai_lin_norm(A:,i:,u:)]',\n",
    "    'Divergence[roys_root_lin_norm(A:,i:,u:)]',\n",
    "    'Divergence[hotelling_lin_norm(A:,i:,u:)]',\n",
    "    'Divergence[Between_Within_Det_ratio_norm(A:,i:,u:)]',\n",
    "    'Divergence[Between_Within_Tr_ratio_norm(A:,i:,u:)]',\n",
    "    'Divergence[within_covariance_norm(A:,i:,u:)]_var_p1',\n",
    "    'Divergence[within_variance_norm(A:,i:,u:)]_var_p1',\n",
    "    'Divergence[between_covariance_norm(A:,i:,u:)]_var_p1',\n",
    "    'Divergence[between_variance_norm(A:,i:,u:)]_var_p1',\n",
    "    'Divergence[total_covariance_norm(A:,i:,u:)]_var_p1', \n",
    "    'Divergence[total_variance_norm(A:,i:,u:)]_var_p1',\n",
    "    'Divergence[sam_wilks_lin_norm(A:,i:,u:)]_var_p1',\n",
    "    'Divergence[pillai_lin_norm(A:,i:,u:)]_var_p1',\n",
    "    'Divergence[roys_root_lin_norm(A:,i:,u:)]_var_p1',\n",
    "    'Divergence[hotelling_lin_norm(A:,i:,u:)]_var_p1',\n",
    "    'Divergence[Between_Within_Det_ratio_norm(A:,i:,u:)]_var_p1',\n",
    "    'Divergence[Between_Within_Tr_ratio_norm(A:,i:,u:)]_var_p1',\n",
    "    'Divergence[within_covariance_norm(A:,i:,u:)]_var_p2',    \n",
    "    'Divergence[within_variance_norm(A:,i:,u:)]_var_p2',    \n",
    "    'Divergence[between_covariance_norm(A:,i:,u:)]_var_p2',    \n",
    "    'Divergence[between_variance_norm(A:,i:,u:)]_var_p2',\n",
    "    'Divergence[total_covariance_norm(A:,i:,u:)]_var_p2', \n",
    "    'Divergence[total_variance_norm(A:,i:,u:)]_var_p2',\n",
    "    'Divergence[sam_wilks_lin_norm(A:,i:,u:)]_var_p2',\n",
    "    'Divergence[pillai_lin_norm(A:,i:,u:)]_var_p2',\n",
    "    'Divergence[roys_root_lin_norm(A:,i:,u:)]_var_p2',\n",
    "    'Divergence[hotelling_lin_norm(A:,i:,u:)]_var_p2',\n",
    "    'Divergence[Between_Within_Det_ratio_norm(A:,i:,u:)]_var_p2',\n",
    "    'Divergence[Between_Within_Tr_ratio_norm(A:,i:,u:)]_var_p2',\n",
    "    ]\n",
    "\n",
    "\n",
    "featuresOfInterest_manual=[ [col] for col in columns]\n",
    "# featuresOfInterest_manual=[ [col] + ['u_num+i_num+a_num'] for col in columns]\n",
    "\n",
    "\n",
    "label_choose=['ADOS_C']\n",
    "\n",
    "FeatureLabelMatch_manual=[]\n",
    "df_formant_statistics_CtxPhone_collect_dict=Dict()\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "class ADOSdataset():\n",
    "    def __init__(self,knn_weights,knn_neighbors,Reorder_type,FeatureComb_mode):\n",
    "        self.featurepath='Features'           \n",
    "        self.FeatureComb_mode=FeatureComb_mode\n",
    "        self.N=2\n",
    "        self.LabelType=Dict()\n",
    "        self.LabelType['ADOS_C']='regression'\n",
    "        self.LabelType['ADOS_cate_C']='classification'\n",
    "        self.LabelType['ASDTD']='classification'\n",
    "        # self.Fractionfeatures_str='Features/artuculation_AUI/Vowels/Fraction/*.pkl'  #Fractions好像不太會用到了   \n",
    "        \n",
    "        \n",
    "        # self.Merge_feature_path='Features/ClassificationMerged_dfs/{dataset_role}/*.pkl'.format(dataset_role='ASD_DOCKID')\n",
    "        \n",
    "        if self.FeatureComb_mode == 'Add_UttLvl_feature':\n",
    "            self.File_root_path='Features/ClassificationMerged_dfs/ADDed_UttFeat/{knn_weights}_{knn_neighbors}_{Reorder_type}/'.format(knn_weights=knn_weights,knn_neighbors=knn_neighbors,Reorder_type=Reorder_type)\n",
    "            self.Merge_feature_path=self.File_root_path+'{dataset_role}/*.pkl'.format(dataset_role='ASD_DOCKID')\n",
    "        else:\n",
    "            self.File_root_path='Features/ClassificationMerged_dfs/{knn_weights}_{knn_neighbors}_{Reorder_type}/'.format(knn_weights=knn_weights,knn_neighbors=knn_neighbors,Reorder_type=Reorder_type)\n",
    "            self.Merge_feature_path=self.File_root_path+'{dataset_role}/*.pkl'.format(dataset_role='ASD_DOCKID')\n",
    "        \n",
    "        self.Top_ModuleColumn_mapping_dict={}\n",
    "        self.Top_ModuleColumn_mapping_dict['Add_UttLvl_feature']=FeatSel.Columns_comb2.copy()\n",
    "        self.Top_ModuleColumn_mapping_dict['feat_comb']=FeatSel.Columns_comb.copy()\n",
    "        self.Top_ModuleColumn_mapping_dict['feat_comb3']=FeatSel.Columns_comb3.copy()\n",
    "        self.Top_ModuleColumn_mapping_dict['feat_comb5']=FeatSel.Columns_comb5.copy()\n",
    "        self.Top_ModuleColumn_mapping_dict['feat_comb6']=FeatSel.Columns_comb6.copy()\n",
    "        self.Top_ModuleColumn_mapping_dict['feat_comb7']=FeatSel.Columns_comb7.copy()\n",
    "        self.Top_ModuleColumn_mapping_dict['Comb_dynPhonation']=FeatSel.Comb_dynPhonation.copy()\n",
    "        self.Top_ModuleColumn_mapping_dict['Comb_staticLOCDEP_dynamicLOCDEP_dynamicphonation']=FeatSel.Comb_staticLOCDEP_dynamicLOCDEP_dynamicphonation.copy()\n",
    "        self.Top_ModuleColumn_mapping_dict['baselineFeats']=FeatSel.Baseline_comb.copy()\n",
    "        \n",
    "        self.FeatureCombs_manual=Dict()\n",
    "        self.FeatureCombs_manual['TD_normal vs ASDSevere_agesexmatch >> FeatLOC_kid']=['df_formant_statistic_TD_normal_kid', 'df_formant_statistic_agesexmatch_ASDSevereGrp_kid']\n",
    "        self.FeatureCombs_manual['TD_normal vs ASDMild_agesexmatch >> FeatLOC_kid']=['df_formant_statistic_TD_normal_kid', 'df_formant_statistic_agesexmatch_ASDMildGrp_kid']\n",
    "        self.FeatureCombs_manual['TD_normal vs ASDSevere_agesexmatch >> FeatLOC_doc']=['df_formant_statistic_TD_normal_doc', 'df_formant_statistic_agesexmatch_ASDSevereGrp_doc']\n",
    "        self.FeatureCombs_manual['TD_normal vs ASDMild_agesexmatch >> FeatLOC_doc']=['df_formant_statistic_TD_normal_doc', 'df_formant_statistic_agesexmatch_ASDMildGrp_doc']\n",
    "        self.FeatureCombs_manual['TD_normal vs ASDSevere_agesexmatch >> FeatLOC_DKRatio']=['df_formant_statistic_TD_normalGrp_DKRatio', 'df_formant_statistic_agesexmatch_ASDSevereGrp_DKRatio']\n",
    "        self.FeatureCombs_manual['TD_normal vs ASDMild_agesexmatch >> FeatLOC_DKRatio']=['df_formant_statistic_TD_normalGrp_DKRatio', 'df_formant_statistic_agesexmatch_ASDMildGrp_DKRatio']\n",
    "        \n",
    "        self.FeatureCombs_manual['TD_normal vs ASDSevere_agesexmatch >> FeatCoor']=['df_syncrony_statistic_TD_normalGrp', 'df_syncrony_statistic_agesexmatch_ASDSevereGrp']\n",
    "        self.FeatureCombs_manual['TD_normal vs ASDMild_agesexmatch >> FeatCoor']=['df_syncrony_statistic_TD_normalGrp', 'df_syncrony_statistic_agesexmatch_ASDMildGrp']\n",
    "        # self.FeatureCombs_manual['Notautism vs ASD']=['df_formant_statistic_77_Notautism', 'df_formant_statistic_77_ASD']\n",
    "        # self.FeatureCombs_manual['ASD vs Autism']=['df_formant_statistic_77_ASD', 'df_formant_statistic_77_Autism']\n",
    "        # self.FeatureCombs_manual['Notautism vs Autism']=['df_formant_statistic_77_Notautism', 'df_formant_statistic_77_Autism']\n",
    "    \n",
    "        # self._FeatureBuild_single()\n",
    "        self._FeatureBuild_Module()\n",
    "    def Get_FormantAUI_feat(self,label_choose,pickle_path,featuresOfInterest=['MSB_f1','MSB_f2','MSB_mix'],filterbyNum=True,**kwargs):\n",
    "        arti=articulation.articulation.Articulation()\n",
    "        \n",
    "        \n",
    "        #如果path有放的話字串的話，就使用path的字串，不然就使用「feat_」等於的東西，在function裡面會以kwargs的形式出現\n",
    "        \n",
    "        if not kwargs and len(pickle_path)>0:\n",
    "            df_tmp=pickle.load(open(pickle_path,\"rb\")).sort_index()\n",
    "        elif len(kwargs)>0: # usage Get_FormantAUI_feat(...,key1=values1):\n",
    "            for k, v in kwargs.items(): #there will be only one element\n",
    "                df_tmp=kwargs[k].sort_index()\n",
    "\n",
    "        if filterbyNum:\n",
    "            df_tmp=arti.BasicFilter_byNum(df_tmp,N=self.N)\n",
    "\n",
    "        if label_choose not in df_tmp.columns:\n",
    "            for people in df_tmp.index:\n",
    "                lab=Label.label_raw[label_choose][Label.label_raw['name']==people]\n",
    "                df_tmp.loc[people,'ADOS']=lab.values\n",
    "            df_y=df_tmp['ADOS'] #Still keep the form of dataframe\n",
    "        else:\n",
    "            df_y=df_tmp[label_choose] #Still keep the form of dataframe\n",
    "        \n",
    "        \n",
    "        feature_array=df_tmp[featuresOfInterest]\n",
    "        \n",
    "            \n",
    "        LabType=self.LabelType[label_choose]\n",
    "        return feature_array, df_y, LabType\n",
    "    def _FeatureBuild_single(self):\n",
    "        Features=Dict()\n",
    "        Features_comb=Dict()\n",
    "        files = glob.glob(self.Fractionfeatures_str)\n",
    "        for file in files:\n",
    "            feat_name=os.path.basename(file).replace(\".pkl\",\"\")\n",
    "            df_tmp=pickle.load(open(file,\"rb\")).sort_index()\n",
    "            Features[feat_name]=df_tmp\n",
    "        for keys in self.FeatureCombs_manual.keys():\n",
    "            combF=[Features[k] for k in self.FeatureCombs_manual[keys]]\n",
    "            Features_comb[keys]=pd.concat(combF)\n",
    "        \n",
    "        self.Features_comb_single=Features_comb\n",
    "    def _FeatureBuild_Module(self):\n",
    "        Labels_add=['ASDTD']\n",
    "        ModuledFeatureCombination=self.Top_ModuleColumn_mapping_dict[self.FeatureComb_mode]\n",
    "\n",
    "        \n",
    "        sellect_people_define=SellectP_define()\n",
    "        #Loading features from ASD        \n",
    "        Features_comb=Dict()\n",
    "        IterateFilesFullPaths = glob.glob(self.Merge_feature_path)\n",
    "        print(\"Search path from \", self.Merge_feature_path)\n",
    "        \n",
    "        if self.FeatureComb_mode in ['feat_comb3','feat_comb5','feat_comb6','feat_comb7','Comb_staticLOCDEP_dynamicLOCDEP_dynamicphonation']:\n",
    "            DfCombFilenames=['static_feautre_LOC+dynamic_feature_LOC+dynamic_feature_phonation.pkl']\n",
    "        if self.FeatureComb_mode == 'Comb_dynPhonation':\n",
    "            DfCombFilenames=['dynamic_feature_phonation.pkl']\n",
    "        elif self.FeatureComb_mode == 'baselineFeats':\n",
    "             DfCombFilenames=['{}.pkl'.format(Dataname) for Dataname in ModuledFeatureCombination.keys()]\n",
    "        else:\n",
    "            DfCombFilenames=[os.path.basename(f) for f in IterateFilesFullPaths]\n",
    "        File_ASD_paths=[self.File_root_path+\"ASD_DOCKID/\"+f for f in DfCombFilenames]\n",
    "        File_TD_paths=[self.File_root_path+\"TD_DOCKID/\"+f for f in DfCombFilenames]\n",
    "        print(\"Read path from \", File_ASD_paths)\n",
    "        print(\"Read path from \", File_TD_paths)\n",
    "        \n",
    "        df_Top_Check_length=pd.DataFrame()\n",
    "        for file_ASD, file_TD in zip(File_ASD_paths,File_TD_paths):\n",
    "            if not os.path.exists(file_ASD) or not os.path.exists(file_TD):\n",
    "                raise FileExistsError()\n",
    "            \n",
    "            assert os.path.basename(file_ASD) == os.path.basename(file_TD)\n",
    "            filename=os.path.basename(file_ASD)\n",
    "            k_FeatTypeLayer1=filename.replace(\".pkl\",\"\")\n",
    "            df_feature_ASD=pickle.load(open(file_ASD,\"rb\")).sort_index()\n",
    "            df_feature_TD=pickle.load(open(file_TD,\"rb\")).sort_index()\n",
    "            df_feature_ASD['ASDTD']=sellect_people_define.ASDTD_label['ASD']\n",
    "            df_feature_TD['ASDTD']=sellect_people_define.ASDTD_label['TD']\n",
    "            \n",
    "            # ADD label\n",
    "            df_feature_ASD=Add_label(df_feature_ASD,Label,label_choose='ADOS_cate_CSS')\n",
    "            df_feature_ASD=Add_label(df_feature_ASD,Label,label_choose='ADOS_cate_C')\n",
    "            df_feature_ASD=Add_label(df_feature_ASD,Label,label_choose='ADOS_cate_S')\n",
    "            df_feature_ASD=Add_label(df_feature_ASD,Label,label_choose='ADOS_cate_SC')\n",
    "            df_feature_ASD=Add_label(df_feature_ASD,Label,label_choose='age_year')\n",
    "            df_feature_ASD=Add_label(df_feature_ASD,Label,label_choose='sex')\n",
    "            # create different ASD cohort\n",
    "            filter_Minimal_TCSS=df_feature_ASD['ADOS_cate_CSS']==0\n",
    "            filter_low_TCSS=df_feature_ASD['ADOS_cate_CSS']==1\n",
    "            filter_moderate_TCSS=df_feature_ASD['ADOS_cate_CSS']==2\n",
    "            filter_high_TCSS=df_feature_ASD['ADOS_cate_CSS']==3\n",
    "            \n",
    "            filter_Notautism_TC=df_feature_ASD['ADOS_cate_C']==0\n",
    "            filter_ASD_TC=df_feature_ASD['ADOS_cate_C']==1\n",
    "            filter_Autism_TC=df_feature_ASD['ADOS_cate_C']==2\n",
    "            \n",
    "            filter_Notautism_TS=df_feature_ASD['ADOS_cate_S']==0\n",
    "            filter_ASD_TS=df_feature_ASD['ADOS_cate_S']==1\n",
    "            filter_Autism_TS=df_feature_ASD['ADOS_cate_S']==2\n",
    "            \n",
    "            filter_Notautism_TSC=df_feature_ASD['ADOS_cate_SC']==0\n",
    "            filter_ASD_TSC=df_feature_ASD['ADOS_cate_SC']==1\n",
    "            filter_Autism_TSC=df_feature_ASD['ADOS_cate_SC']==2\n",
    "            \n",
    "            df_feauture_ASDgrp_dict={}\n",
    "            # df_feauture_ASDgrp_dict['df_feature_Minimal_CSS']=df_feature_ASD[filter_Minimal_TCSS]\n",
    "            # df_feauture_ASDgrp_dict['df_feature_low_CSS']=df_feature_ASD[filter_low_TCSS]\n",
    "            df_feauture_ASDgrp_dict['df_feature_lowMinimal_CSS']=df_feature_ASD[filter_low_TCSS | filter_Minimal_TCSS]\n",
    "            df_feauture_ASDgrp_dict['df_feature_moderate_CSS']=df_feature_ASD[filter_moderate_TCSS]\n",
    "            df_feauture_ASDgrp_dict['df_feature_high_CSS']=df_feature_ASD[filter_high_TCSS]\n",
    "\n",
    "            \n",
    "            #Check the length of each paired comparison, should be stored on the top of for loop\n",
    "            \n",
    "            Tmp_Numcmp_dict={}\n",
    "            for key in df_feauture_ASDgrp_dict.keys():\n",
    "                Numcmp_str='ASD({0}) vs TD({1})'.format(len(df_feauture_ASDgrp_dict[key]),len(df_feature_TD))\n",
    "                Numcmp_str_Total='ASD({0}) vs TD({1})'.format(len(df_feature_ASD),len(df_feature_TD))\n",
    "                Tmp_Numcmp_dict[key]=Numcmp_str\n",
    "                Tmp_Numcmp_dict['ASD vs TD']=Numcmp_str_Total\n",
    "                \n",
    "            \n",
    "            df_Tmp_Numcmp_list=pd.DataFrame.from_dict(Tmp_Numcmp_dict,orient='index')\n",
    "            df_Tmp_Numcmp_list.columns=[k_FeatTypeLayer1]\n",
    "\n",
    "            if len(df_Top_Check_length)==0:\n",
    "                df_Top_Check_length=df_Tmp_Numcmp_list\n",
    "            else:\n",
    "                df_Top_Check_length=Merge_dfs(df_Top_Check_length,df_Tmp_Numcmp_list)\n",
    "            # 手動執行到這邊，從for 上面\n",
    "            \n",
    "            \n",
    "            for k_FeatTypeLayer2 in ModuledFeatureCombination[k_FeatTypeLayer1].keys():\n",
    "                colums_sel=ModuledFeatureCombination[k_FeatTypeLayer1][k_FeatTypeLayer2]\n",
    "                \n",
    "                # 1. Set ASD vs TD experiment\n",
    "                for k_ASDgrp in df_feauture_ASDgrp_dict.keys():\n",
    "                    df_ASD_subgrp=df_feauture_ASDgrp_dict[k_ASDgrp].copy()[colums_sel+Labels_add]\n",
    "                    df_TD_subgrp=df_feature_TD.copy()[colums_sel+Labels_add]\n",
    "                    \n",
    "                    experiment_str=\"{TD_name} vs {ASD_name} >> {feature_type}\".format(TD_name='TD',ASD_name=k_ASDgrp,feature_type=k_FeatTypeLayer2)\n",
    "                    Features_comb[experiment_str]=pd.concat([df_ASD_subgrp,df_TD_subgrp],axis=0)\n",
    "                # 2. Set ASDsevere vs ASDmild experiment\n",
    "                    \n",
    "                # experiment_str=\"{ASDsevere_name} vs {ASDmild_name} >> {feature_type}\".format(ASDsevere_name='df_feature_moderatehigh_CSS',ASDmild_name='df_feature_lowMinimal_CSS',feature_type=k_FeatTypeLayer2)\n",
    "                # df_ASDsevere_subgrp=df_feauture_ASDgrp_dict['df_feature_moderatehigh_CSS'].copy()\n",
    "                # df_ASDmild_subgrp=df_feauture_ASDgrp_dict['df_feature_lowMinimal_CSS'].copy()\n",
    "                # df_ASDsevere_subgrp['ASDsevereMild']=sellect_people_define.ASDsevereMild_label['ASDsevere']\n",
    "                # df_ASDmild_subgrp['ASDsevereMild']=sellect_people_define.ASDsevereMild_label['ASDmild']\n",
    "                # Features_comb[experiment_str]=pd.concat([df_ASDsevere_subgrp,df_ASDmild_subgrp],axis=0)\n",
    "        self.Features_comb_multi=Features_comb\n",
    "\n",
    "def MERGEFEATURES():\n",
    "    # =============================================================================\n",
    "    '''\n",
    "\n",
    "        Feature merging function\n",
    "        \n",
    "        Ths slice of code provide user to manually make functions to combine df_XXX_infos\n",
    "\n",
    "    '''\n",
    "    # =============================================================================\n",
    "    if args.Mergefeatures:\n",
    "        # dataset_role='ASD_DOCKID'\n",
    "        for dataset_role in ['ASD_DOCKID','TD_DOCKID']:\n",
    "            Merg_filepath={}\n",
    "            Merg_filepath['static_feautre_LOC']='Features/artuculation_AUI/Vowels/Formants/Formant_AUI_tVSAFCRFvals_KID_From{dataset_role}.pkl'.format(dataset_role=dataset_role)\n",
    "            Merg_filepath['static_feautre_phonation']='Features/artuculation_AUI/Vowels/Phonation/Phonation_meanvars_KID_From{dataset_role}.pkl'.format(dataset_role=dataset_role)\n",
    "            Merg_filepath['dynamic_feature_LOC']='Features/artuculation_AUI/Interaction/Formants/Syncrony_measure_of_variance_DKIndividual_{dataset_role}.pkl'.format(dataset_role=dataset_role)\n",
    "            Merg_filepath['dynamic_feature_phonation']='Features/artuculation_AUI/Interaction/Phonation/Syncrony_measure_of_variance_phonation_{dataset_role}.pkl'.format(dataset_role=dataset_role)\n",
    "            \n",
    "            merge_out_path='Features/ClassificationMerged_dfs/{dataset_role}/'.format(dataset_role=dataset_role)\n",
    "            if not os.path.exists(merge_out_path):\n",
    "                os.makedirs(merge_out_path)\n",
    "            \n",
    "            df_infos_dict=Dict()\n",
    "            for keys, paths in Merg_filepath.items():\n",
    "                df_infos_dict[keys]=pickle.load(open(paths,\"rb\")).sort_index()\n",
    "            \n",
    "            Merged_df_dict=Dict()\n",
    "            comb1 = list(combinations(list(Merg_filepath.keys()), 1))\n",
    "            comb2 = list(combinations(list(Merg_filepath.keys()), 2))\n",
    "            for c in comb1:\n",
    "                e1=c[0]\n",
    "                Merged_df_dict[e1]=df_infos_dict[e1]\n",
    "                OutPklpath=merge_out_path+ e1 + \".pkl\"\n",
    "                pickle.dump(Merged_df_dict[e1],open(OutPklpath,\"wb\"))\n",
    "                \n",
    "                \n",
    "            for c in comb2:\n",
    "                e1, e2=c\n",
    "                Merged_df_dict['+'.join(c)]=Merge_dfs(df_infos_dict[e1],df_infos_dict[e2])\n",
    "                \n",
    "                OutPklpath=merge_out_path+'+'.join(c)+\".pkl\"\n",
    "                pickle.dump(Merged_df_dict['+'.join(c)],open(OutPklpath,\"wb\"))\n",
    "\n",
    "\n",
    "\n",
    "ados_ds=ADOSdataset(knn_weights,knn_neighbors,Reorder_type,FeatureComb_mode=args.FeatureComb_mode)\n",
    "ErrorFeat_bookeep=Dict()\n",
    "\n",
    "\n",
    "# FeatureLabelMatch=FeatureLabelMatch_manual\n",
    "\n",
    "# 在這邊生出要執行的feature實驗\n",
    "\n",
    "# FeatureLabelMatch=[ [k,'ASDTD'] for k in ados_ds.Features_comb_multi.keys()] ## Only ASD vs TD setting\n",
    "\n",
    "## ASD 之間互比的setting\n",
    "FeatureLabelMatch=[]\n",
    "for k in ados_ds.Features_comb_multi.keys():\n",
    "    Compare_pair_str=k.split(\" >> \")[0]\n",
    "    if 'TD' in Compare_pair_str:\n",
    "        FeatureLabelMatch.append([k,'ASDTD'])\n",
    "    else:\n",
    "        FeatureLabelMatch.append([k,'ASDsevereMild'])\n",
    "\n",
    "## Feature 組合為comb3 的 ASD vs TD setting\n",
    "# FeatureLabelMatch=[]\n",
    "# for k in ados_ds.Features_comb_multi.keys():\n",
    "#     Compare_pair_str=k.split(\" >> \")[0]\n",
    "#     Feat_comb_str=k.split(\" >> \")[1]\n",
    "#     if Feat_comb_str in FeatSel.Columns_comb3['static_feautre_LOC+dynamic_feature_LOC+dynamic_feature_phonation'].keys():\n",
    "#         FeatureLabelMatch.append([k,'ASDTD'])\n",
    "\n",
    "Top_ModuleColumn_mapping_dict={}\n",
    "Top_ModuleColumn_mapping_dict['Add_UttLvl_feature']={ e2_str:FeatSel.Columns_comb2[e_str][e2_str] for e_str in FeatSel.Columns_comb2.keys() for e2_str in FeatSel.Columns_comb2[e_str].keys()}\n",
    "Top_ModuleColumn_mapping_dict['feat_comb3']=ModuleColumn_mapping={ e2_str:FeatSel.Columns_comb3[e_str][e2_str] for e_str in FeatSel.Columns_comb3.keys() for e2_str in FeatSel.Columns_comb3[e_str].keys()}\n",
    "Top_ModuleColumn_mapping_dict['feat_comb5']=ModuleColumn_mapping={ e2_str:FeatSel.Columns_comb5[e_str][e2_str] for e_str in FeatSel.Columns_comb5.keys() for e2_str in FeatSel.Columns_comb5[e_str].keys()}\n",
    "Top_ModuleColumn_mapping_dict['feat_comb6']=ModuleColumn_mapping={ e2_str:FeatSel.Columns_comb6[e_str][e2_str] for e_str in FeatSel.Columns_comb6.keys() for e2_str in FeatSel.Columns_comb6[e_str].keys()}\n",
    "Top_ModuleColumn_mapping_dict['feat_comb7']=ModuleColumn_mapping={ e2_str:FeatSel.Columns_comb7[e_str][e2_str] for e_str in FeatSel.Columns_comb7.keys() for e2_str in FeatSel.Columns_comb7[e_str].keys()}\n",
    "Top_ModuleColumn_mapping_dict['Comb_dynPhonation']=ModuleColumn_mapping={ e2_str:FeatSel.Comb_dynPhonation[e_str][e2_str] for e_str in FeatSel.Comb_dynPhonation.keys() for e2_str in FeatSel.Comb_dynPhonation[e_str].keys()}\n",
    "Top_ModuleColumn_mapping_dict['Comb_staticLOCDEP_dynamicLOCDEP_dynamicphonation']=ModuleColumn_mapping={ e2_str:FeatSel.Comb_staticLOCDEP_dynamicLOCDEP_dynamicphonation[e_str][e2_str] for e_str in FeatSel.Comb_staticLOCDEP_dynamicLOCDEP_dynamicphonation.keys() for e2_str in FeatSel.Comb_staticLOCDEP_dynamicLOCDEP_dynamicphonation[e_str].keys()}\n",
    "Top_ModuleColumn_mapping_dict['baselineFeats']=ModuleColumn_mapping={ e2_str:FeatSel.Baseline_comb[e_str][e2_str] for e_str in FeatSel.Baseline_comb.keys() for e2_str in FeatSel.Baseline_comb[e_str].keys()}\n",
    "Top_ModuleColumn_mapping_dict['feat_comb']=ModuleColumn_mapping={ e2_str:FeatSel.Columns_comb[e_str][e2_str] for e_str in FeatSel.Columns_comb.keys() for e2_str in FeatSel.Columns_comb[e_str].keys()}\n",
    "\n",
    "\n",
    "ModuleColumn_mapping=Top_ModuleColumn_mapping_dict[args.FeatureComb_mode]\n",
    "\n",
    "    \n",
    "for exp_str,lab_ in FeatureLabelMatch:\n",
    "    ModuleColumn_str=exp_str.split(\" >> \")[-1]\n",
    "    \n",
    "    if len(FeatureLabelMatch_manual)==0:\n",
    "        featuresOfInterest=[ModuleColumn_mapping[ModuleColumn_str]]\n",
    "    else:\n",
    "        featuresOfInterest=FeatureLabelMatch_manual\n",
    "    \n",
    "    # feat_=key\n",
    "    for feat_col in featuresOfInterest:\n",
    "        feat_col_ = list(feat_col) # ex: ['MSB_f1']\n",
    "        if len(feat_col) > 144:\n",
    "            key=feat_col_\n",
    "        else:\n",
    "            key=[ModuleColumn_str]\n",
    "        \n",
    "        X,y, featType=ados_ds.Get_FormantAUI_feat(\\\n",
    "            label_choose=lab_,pickle_path='',featuresOfInterest=feat_col_,filterbyNum=False,\\\n",
    "            feat_=ados_ds.Features_comb_multi[exp_str])\n",
    "        \n",
    "        if X.isnull().values.any() or y.isnull().values.any():\n",
    "            print(\"Feat: \",key,'Contains nan')\n",
    "            ErrorFeat_bookeep['{0} {1} {2}'.format(exp_str,lab_,key)].X=X\n",
    "            ErrorFeat_bookeep['{0} {1} {2}'.format(exp_str,lab_,key)].y=y\n",
    "            continue\n",
    "        \n",
    "        Item_name=\"{feat}::{lab}\".format(feat='-'.join([exp_str]),lab=lab_)\n",
    "        Session_level_all[Item_name].X, \\\n",
    "            Session_level_all[Item_name].y, \\\n",
    "                Session_level_all[Item_name].feattype = X,y, featType\n",
    "\n",
    "# =============================================================================\n",
    "# Model parameters\n",
    "# =============================================================================\n",
    "C_variable=np.array([0.001,0.01,0.1,1,5,10.0,25,50,75,100])\n",
    "n_estimator=[ 32, 50, 64, 100 ,128, 256]\n",
    "\n",
    "'''\n",
    "\n",
    "    Classifier\n",
    "\n",
    "'''\n",
    "\n",
    "# This is the closest \n",
    "Classifier={}\n",
    "Classifier['SVC']={'model':sklearn.svm.SVC(),\\\n",
    "                  'parameters':{'model__random_state':[1],\\\n",
    "                      'model__C':C_variable,\\\n",
    "                    'model__kernel': ['rbf'],\\\n",
    "                      # 'model__gamma':['auto'],\\\n",
    "                    'model__probability':[True],\\\n",
    "                                }}\n",
    "\n",
    "\n",
    "loo=LeaveOneOut()\n",
    "# CV_settings=loo\n",
    "CV_settings=10\n",
    "\n",
    "# =============================================================================\n",
    "# Outputs\n",
    "Best_predict_optimize={}\n",
    "\n",
    "df_best_result_r2=pd.DataFrame([])\n",
    "df_best_result_pear=pd.DataFrame([])\n",
    "df_best_result_spear=pd.DataFrame([])\n",
    "df_best_cross_score=pd.DataFrame([])\n",
    "df_best_result_UAR=pd.DataFrame([])\n",
    "df_best_result_AUC=pd.DataFrame([])\n",
    "df_best_result_f1=pd.DataFrame([])\n",
    "df_best_result_allThreeClassifiers=pd.DataFrame([])\n",
    "# =============================================================================\n",
    "\n",
    "Result_path=\"RESULTS/Fusion_result/{}/\".format(args.FeatureComb_mode)\n",
    "\n",
    "if not os.path.exists(Result_path):\n",
    "    os.makedirs(Result_path)\n",
    "final_result_file=\"_ADOS_{}.xlsx\".format(args.suffix)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "count=0\n",
    "OutFeature_dict=Dict()\n",
    "Best_param_dict=Dict()\n",
    "\n",
    "print(\"Start classification\")\n",
    "print(\"\\n\\n\\n\\n\")\n",
    "\n",
    "for clf_keys, clf in Classifier.items(): #Iterate among different classifiers \n",
    "    writer_clf = pd.ExcelWriter(Result_path+\"/\"+clf_keys+\"_\"+args.Feature_mode+\"_\"+final_result_file, engine = 'xlsxwriter')\n",
    "    # for feature_lab_str in dropwhile(lambda k: k != 'TD vs df_feature_lowMinimal_CSS >> LOC_columns+DEP_columns+LOCDEP_Proximity_cols+LOCDEP_Convergence_cols+LOCDEP_Syncrony_cols+Phonation_Trend_D_cols+Phonation_Trend_K_cols+Phonation_Proximity_cols+Phonation_Convergence_cols+Phonation_Syncrony_cols::ASDTD', Session_level_all):\n",
    "    #     features=Session_level_all[feature_lab_str]\n",
    "    for feature_lab_str, features in Session_level_all.items():\n",
    "        feature_keys, label_keys= feature_lab_str.split(\"::\")\n",
    "        feature_rawname=feature_keys[re.search(' >> ',feature_keys).end():]\n",
    "        # # change the feature name to paper name\n",
    "        if feature_rawname in PprNmeMp.Paper_name_map.keys():\n",
    "            featurename_paper=PprNmeMp.Paper_name_map[feature_rawname]\n",
    "            feature_keys=feature_keys.replace(feature_rawname,featurename_paper)\n",
    "            \n",
    "        \n",
    "        Labels = Session_level_all.X[feature_keys]\n",
    "        print(\"=====================Cross validation start==================\")\n",
    "        pipe = Pipeline(steps=[('scalar',StandardScaler()),(\"model\", clf['model'])])\n",
    "        p_grid=clf['parameters']\n",
    "        Gclf = GridSearchCV(estimator=pipe, param_grid=p_grid, scoring=args.selectModelScoring, cv=CV_settings, refit=True, n_jobs=-1)\n",
    "        # Score=cross_val_score(Gclf, features.X, features.y, cv=loo) \n",
    "        CVpredict=cross_val_predict(Gclf, features.X, features.y, cv=CV_settings)           \n",
    "        Gclf.fit(features.X,features.y)\n",
    "        if clf_keys == \"EN\":\n",
    "            print('The coefficient of best estimator is: ',Gclf.best_estimator_.coef_)\n",
    "        \n",
    "        print(\"The best score with scoring parameter: 'r2' is\", Gclf.best_score_)\n",
    "        print(\"The best parameters are :\", Gclf.best_params_)\n",
    "        best_parameters=Gclf.best_params_\n",
    "        best_score=Gclf.best_score_\n",
    "        best_parameters.update({'best_score':best_score})\n",
    "        Best_param_dict[feature_lab_str]=best_parameters\n",
    "        cv_results_info=Gclf.cv_results_\n",
    "\n",
    "        \n",
    "        \n",
    "        if features.feattype == 'regression':\n",
    "            r2=r2_score(features.y,CVpredict )\n",
    "            n,p=features.X.shape\n",
    "            r2_adj=1-(1-r2)*(n-1)/(n-p-1)\n",
    "            pearson_result, pearson_p=pearsonr(features.y,CVpredict )\n",
    "            spear_result, spearman_p=spearmanr(features.y,CVpredict )\n",
    "            print('Feature {0}, label {1} ,spear_result {2}'.format(feature_keys, label_keys,spear_result))\n",
    "        elif features.feattype == 'classification':\n",
    "            n,p=features.X.shape\n",
    "            UAR=recall_score(features.y, CVpredict, average='macro')\n",
    "            AUC=roc_auc_score(features.y, CVpredict)\n",
    "            f1Score=f1_score(features.y, CVpredict, average='macro')\n",
    "            print('Feature {0}, label {1} ,UAR {2}'.format(feature_keys, label_keys,UAR))\n",
    "        \n",
    "        if args.Plot and p <2:\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(15, 10), sharey=True)\n",
    "            kernel_label = [clf_keys]\n",
    "            model_color = ['m']\n",
    "            # axes.plot((features.X - min(features.X) )/ max(features.X), Gclf.best_estimator_.fit(features.X,features.y).predict(features.X), color=model_color[0],\n",
    "            #               label='CV Predict')\n",
    "            axes.scatter((features.X.values - min(features.X.values) )/ max(features.X.values), CVpredict, \n",
    "                         facecolor=\"none\", edgecolor=\"k\", s=150,\n",
    "                         label='{}'.format(feature_lab_str)\n",
    "                         )\n",
    "            axes.scatter((features.X.values - min(features.X.values) )/ max(features.X.values), features.y, \n",
    "                         facecolor=\"none\", edgecolor=\"r\", s=50,\n",
    "                         label='Real Y')\n",
    "            axes.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1),\n",
    "                    ncol=1, fancybox=True, shadow=True)\n",
    "            \n",
    "            Plot_path='./Plot/LinearRegress/'\n",
    "            if not os.path.exists(Plot_path):\n",
    "                os.makedirs(Plot_path)\n",
    "            plot_file=Plot_path+\"/{0}_{1}.png\".format(clf_keys,feature_lab_str)\n",
    "            plt.savefig(plot_file, dpi=200) \n",
    "        \n",
    "        # =============================================================================\n",
    "        '''\n",
    "            Inspect the best result\n",
    "        '''\n",
    "        # =============================================================================\n",
    "        # Best_predict_optimize[label_keys]=pd.DataFrame(np.vstack((CVpredict,features.y)).T,columns=['y_pred','y'])\n",
    "        # excel_path='./Statistics/prediction_result'\n",
    "        # if not os.path.exists(excel_path):\n",
    "        #     os.makedirs(excel_path)\n",
    "        # excel_file=excel_path+\"/{0}_{1}.xlsx\"\n",
    "        # writer = pd.ExcelWriter(excel_file.format(clf_keys,feature_keys.replace(\":\",\"\")), engine = 'xlsxwriter')\n",
    "        # for label_name in  Best_predict_optimize.keys():\n",
    "        #     Best_predict_optimize[label_name].to_excel(writer,sheet_name=label_name.replace(\"/\",\"_\"))\n",
    "        # writer.save()\n",
    "                                \n",
    "        # ================================================      =============================\n",
    "        if features.feattype == 'regression':\n",
    "            df_best_result_r2.loc[feature_keys,label_keys]='{0}/{1}'.format(np.round(r2_adj,3),np.round(np.nan,6))\n",
    "            df_best_result_pear.loc[feature_keys,label_keys]='{0}/{1}'.format(np.round(pearson_result,3),np.round(pearson_p,6))\n",
    "            df_best_result_spear.loc[feature_keys,label_keys]='{0}/{1}'.format(np.round(spear_result,3),np.round(spearman_p,6))\n",
    "            df_best_result_spear.loc[feature_keys,'de-zero_num']=len(features.X)\n",
    "            # df_best_cross_score.loc[feature_keys,label_keys]=Score.mean()\n",
    "            df_best_result_allThreeClassifiers.loc[feature_keys,'{0}/{1} (R2adj/pear/spear)'.format(label_keys,clf_keys)]\\\n",
    "                        ='{0}/{1}/{2}'.format(np.round(r2_adj,3),np.round(pearson_result,3),np.round(spear_result,3))\n",
    "\n",
    "        elif features.feattype == 'classification':\n",
    "            df_best_result_UAR.loc[feature_keys,label_keys]='{0}'.format(UAR)\n",
    "            df_best_result_AUC.loc[feature_keys,label_keys]='{0}'.format(AUC)\n",
    "            df_best_result_f1.loc[feature_keys,label_keys]='{0}'.format(f1Score)\n",
    "            # df_best_result_allThreeClassifiers.loc[feature_keys,'{0}/{1} (UAR/AUC/f1score)'.format(label_keys,clf_keys)]\\\n",
    "            #             ='{0}/{1}/{2}'.format(np.round(UAR,3),np.round(AUC,3),np.round(f1Score,3))\n",
    "            df_best_result_allThreeClassifiers.loc[feature_keys,'{0}/{1}'.format(label_keys,clf_keys)]\\\n",
    "                        ='{0}'.format(np.round(UAR,3))\n",
    "            df_best_result_allThreeClassifiers.loc[feature_keys,'f1']\\\n",
    "                        ='{0}'.format(np.round(f1Score,3))\n",
    "            \n",
    "    \n",
    "    if features.feattype == 'regression':\n",
    "        df_best_result_r2.to_excel(writer_clf,sheet_name=\"R2_adj\")\n",
    "        df_best_result_pear.to_excel(writer_clf,sheet_name=\"pear\")\n",
    "        df_best_result_spear.to_excel(writer_clf,sheet_name=\"spear\")\n",
    "        df_best_result_spear.to_csv(Result_path+\"/\"+clf_keys+\"_\"+args.Feature_mode+\"_spearman.csv\")\n",
    "    elif features.feattype == 'classification':\n",
    "        df_best_result_UAR.to_excel(writer_clf,sheet_name=\"UAR\")\n",
    "        df_best_result_AUC.to_excel(writer_clf,sheet_name=\"AUC\")\n",
    "        df_best_result_f1.to_excel(writer_clf,sheet_name=\"f1\")\n",
    "\n",
    "writer_clf.save()\n",
    "df_best_result_allThreeClassifiers.to_excel(Result_path+\"/\"+\"Classification_{knn_weights}_{knn_neighbors}_{Reorder_type}.xlsx\".format(knn_weights=knn_weights,knn_neighbors=knn_neighbors,Reorder_type=Reorder_type))\n",
    "df_best_result_allThreeClassifiers[df_best_result_allThreeClassifiers['ASDTD/SVC'].astype(float)>0.8]\n",
    "\n",
    "print(\"df_best_result_allThreeClassifiers\")\n",
    "print(df_best_result_allThreeClassifiers)\n",
    "print('generated at',Result_path+\"/\"+\"Classification_{knn_weights}_{knn_neighbors}_{Reorder_type}.xlsx\".format(knn_weights=knn_weights,knn_neighbors=knn_neighbors,Reorder_type=Reorder_type) )\n",
    "print(\"\\n\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
